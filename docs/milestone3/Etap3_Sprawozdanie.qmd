---
title: Sprawozdanie Etap 3 - MongoDB
subtitle: Zaawansowane systemy baz danych
format:
  pdf:
    output-file: Etap 3 Sprawozdanie Krzysztof Dąbrowski 293101.pdf
    keep-tex: false
    # fig-pos: 'H'
---

{{< include ../shared/repo_callout.qmd >}}

# Wybrany zbór danych

W liceum zacząłem grać w grę karcianą [\acr{MTG}](https://magic.wizards.com/), która do dziś jest moim hobby.
Gra \acr{MTG} jest bardzo złożona, do tego stopnia, że za pomocą kart i mechanik _można zbudować maszynę Turinga_ @mtg-turing-complete. \
Gra zawiera bardzo wiele kart, z których każda ma zestaw parametrów zależnych od jej typu.
Poza cechami kart związanymi bezpośrednio z rozgrywką, karty mają też dodatkowe cechy takie jak sety, w których zostały wydane, grafikę, która może różnić się między wydaniami, czy też przynależność do talii lub legalność w danych formatach gry.
Istotnym cechą kart są też ich ceny, których zmienność prowadzi nawet do spekulacji cenowych i inwestycji niektórych graczy.

Z uwagi na moje zainteresowanie \acr{MTG}, oraz złożoność danych o kartach i relacji między nimi zdecydowałem się użyć zbioru na ten temat.
W tym celu skorzystałem z projektu MTGJSON @mtgjson:homepage, który jest otwarto źródłowym projektem katalogującym wiele informacji o \acr{MTG} w przenośnych formatach jak na przykład \acr{JSON}.

W ramach projektu dostępne są tysiące zbiorów danych, ponieważ dla każdej oficjalnej talii czy set'u dostępne są dedykowane zbiory.
Postanowiłem się skupić na formacie standard @magic-wizards:standard-format i jednym wybranym secie i talii.
Wybrałem więc zbiory:

- [AllPricesToday](https://mtgjson.com/downloads/all-files/#allpricestoday) - aktualne ceny każdego wydania dla każdej karty
- [DeckList](https://mtgjson.com/downloads/all-files/#decklist) - metadane każdej oficjalnej talii
- [SetList](https://mtgjson.com/downloads/all-files/#setlist) - metadane każdego dodatku
- [Keywords](https://mtgjson.com/downloads/all-files/#keywords) - słowa kluczowe z kart
- [CardTypes](https://mtgjson.com/downloads/all-files/#cardtypes) - typy kart
- [Standard](https://mtgjson.com/downloads/all-files/#standard) - podzbiór wszystkich kart legalnych w formacie standard @magic-wizards:standard-format
- [StandardAtomic](https://mtgjson.com/downloads/all-files/#standardatomic) - podstawowe informacje o kartach legalnych w formacie standard (bez rozróżnienia na różne wydania tej samej karty)
- set Edge of Eternities ([endpoint do pobrania informacji o wybranym dodatku](https://mtgjson.com/downloads/all-sets/))
- deck World Shaper - ([endpoint do pobrania informacji o wybranej talii](https://mtgjson.com/downloads/all-decks/))

Dane zawierają złożone struktury, wiele pól i referencje na dane z innych zbiorów.

# Instalacja MongoDB i wczytanie danych

Przygotowanie bazy MongoDB @mongodb:homepage.

## Instalacja MongoDB

Wybrałem wersję MongoDB Community, ponieważ chciałem skonfigurować lokalną wersję bazy i nie płacić za licencję wersji Enterprise.
Rozważałem też użycie MongoDB Atlas @mongodb:atlas-homepage, ale uznałem, że wolę lokalnie działającą wersję.

Ponieważ w poprzednich etapach dobrze sprawdzała mi się instalacja jako obraz Docker tym razem też się na to zdecydowałem.
Skonfigurowałem uruchomienie obrazu w pliku [`docker-compose.yml`](https://github.com/christopher-dabrowski/BoardBase/blob/main/docker-compose.yml), kierując się oficjalnym poradnikiem Install MongoDB Community Edition @mongodb:install-community-edition. \
Niestety oficjalna strona obrazu wersji community @docker:mongodb-community-server nie opisuje jakie są możliwe tagi, ani jak rozumieć zastosowane w nich skróty. Na szczęście strona do wersji open source obrazu MongoDB @docker:mongodb-official-image jest lepiej opisana. \
Nie byłem pewien, który obraz wybrać, ale sugerując się wątkiem na reddit @reddit:mongo-vs-mongodb-community-server pozostałem przy obrazie `mongodb/mongodb-community-server`. \
Dowiedziałem się, że jest on dostępny w wersji bazującej na Redhat i Ubuntu. Wybrałem wersję na Ubuntu, ponieważ mam większe doświadczenie z tą dystrybucją, choć pewnie nie będzie to miało znaczenia.

Po uruchomieniu kontenera połączyłem się do niego `mongosh` i pobrałem informacje o bazie poleceniem `db.runCommand({hello:1})` jak w samouczku @mongodb:install-community-edition. \
Zobaczyłem \acr{JSON} z informacjami o bazie, co potwierdza, że działą ona poprawnie.

Skonfigurowałem login i hasło użytkownika `root`, żeby ograniczyć dostęp do bazy. \
Rozważałem też ustawienie innych opcji @mongodb:configuration-file, ale uznałem, że na tym etapie domyślne ustawienia mi pasują.

## Wczytanie danych {#sec-data-import}

Na początku spróbowałem wczytać dane za pomocą \acr{Compass} @mongodb:compass.
Zorientowałem się jednak, że ponieważ [moje dane](https://github.com/christopher-dabrowski/BoardBase/tree/main/mongo/data) są pojedynczymi plikami \acr{JSON} to do kolekcji został dodany tylko jeden dokument zawierający wszystkie dane (@fig-compass-import).

![Wczytanie pliku za pomocą MongoDB Compass](img/compass-import.png){#fig-compass-import width=60%}

W dokumentacji przeczytałem, że dobrym sposobem na wczytanie danych z \acr{JSON} jest użycie narzędzia `mongoimport` razem z `jq` do transformacji danych @mongodb:mongoimport-guide.
Skrypty wczytujące dane umieściłem w katalogu [`mongo/importData/`](https://github.com/christopher-dabrowski/BoardBase/tree/main/mongo/importData).

Na początku miałem problem z uwierzytelnieniem. Udało mi się go rozwiązać kodując hasło w connection string używając URL encoding, zgodnie z przykładem z poradnika Decoding Encoded URLs in Linux @baeldung:decoding-encoded-urls-in-linux.

Po wczytaniu danych zauważyłem, że wszystkie pola mają typ `string`.
Przeczytałem, że w przypadku importu z \acr{JSON} wszystkie pola są zapisywane jako `string` @mongodb-community:mongoimport-date-handling.
Przygotowałem więc skrypty `.mongodb.js` w [`mongo/importData/`](https://github.com/christopher-dabrowski/BoardBase/tree/main/mongo/importData), które dostosowują typy we wczytanych dokumentach.

## Podział na kolekcje

Ponieważ projekt MTGJSON @mtgjson:homepage już rozsądnie grupuje różne rodzaje danych, to w mojej bazie załadowałem każdy ze zbiorów danych do osobnej kolekcji.
W przypadku niektórych zbiorów podzieliłem dane na mniejsze dokumenty. Zrobiłem tak na przykład w [`importKeywords.sh`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/importData/importKeywords.sh). \
Gdybym używał danych wielu tali lub setów umieściłbym je wszystkie w kolekcjach `decks` i `sets`. Jednak, ponieważ mam już wiele zestawów danych, to wybrałem tylko po jednej tali i secie.
Utworzone kolekcje są widoczne na @fig-collections.

![Utworzone kolekcje](img/loaded-data.png){#fig-collections}

## Relacje

Wybrane przeze mnie zbiory posiadają już za równo zagniezdzone dokumenty jak i referencje (@fig-nesting-and-reference).
Nie musiałem więc modyfikować ich struktury, poza zmianami, na które zdecydowałem się przy wczytywaniu danych (@sec-data-import).

Różnica między zagnieżdżeniem a referencją polega na tym, że w przypadku zagniezdzenia całe dane są przechowywane w bazowym dokumencie,
a referencja przechowuje tylko identyfikator danych w innym dokumencie. \
Referencja przypomina bardziej znormalizowany model relacyjny.
Stosując MongoDB zalecane jest jednak zagniezdzanie danych, gdy są one często czytane razem, ponieważ znacznie przyśpiesza to regularne działanie bazy @mongodb:data-modeling-best-practices. \

::: {#fig-nesting-and-reference layout="[50, -5, 50]"}

![Przykład zagniezdzonych danych](img/nesting-example.png)

![Przykład referencji](img/reference-example.png)

Przykładowe zagniezdzenie i referencja
:::

Byłem ciekaw jakie są najczęstsze słowa kluczowe w kartach z dodatku _Edge of Eternities_.
W tym celu napisałem zapytanie w pliku [`usingNestedData.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/relations/usingNestedData.mongodb.js), które to wylicza. \
Wynik zapytania z filtrem na 3 najczęstsze słowa kluczowe widać w @lst-eoe-top-3-keywords.

```{#lst-eoe-top-3-keywords .json lst-cap="Top 3 słów kluczowych w dodatku Edge of Eternities"}
{{< include listings/eoeTop3Keywords.json >}}
```

Do pokazania relacji napisałem zapytanie [`mostExpensiveStandardCards.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/relations/mostExpensiveStandardCards.mongodb.js) wyświetlające najdroższe karty legalne w standardzie.
Kolekcja `standard` zawiera informacje o kartach, ale ich aktualne ceny są w kolekcji `allPrices`. Kolekcja `allPrices` zawiera jedynie id kart i dane o cenach.

Zapytanie działało bardzo wolno dla 6440 kart. Prawdopodobnie dodanie indeksów przyśpieszyłoby działanie, ponieważ indeksy są tematem innego etapu, to na razie ograniczyłem liczbę przetwarzanych kart do 100. \
Wyniki zapytania dla 3 najdroższych kart przedstawiam w @lst-most-expensive-standard-cards.

```{#lst-most-expensive-standard-cards .json lst-cap="Top 3 najdroższych kart legalnych w standardzie"}
{{< include listings/mostExpensiveStandardCards.json >}}
```

# Logika biznesowa

Do implementacji logiki biznesowej zdecydowałem się użyć zewnętrznych funkcji w MongoDB Playgrounds @mongodb:playgrounds. \
Rozważałem użycie `$function` @mongodb:function-expression, jednak uznałem, że oferują zbyt małe możliwości do solidnej implementacji logiki biznesowej.
Dodatkowo użycie `$function` nie jest rekomendowane @mongodb:function-expression.

Napisany kod umieściłem w katalogu [`mongo/businessLogic/`](https://github.com/christopher-dabrowski/BoardBase/tree/main/mongo/businessLogic).

- [`addKeyword.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/businessLogic/addKeyword.mongodb.js) - dodaje słowo kluczowe do odpowiedniego dokumentu. Sprawdzana jest poprawność typu słowa kluczowego, a następnie jest ono dodawane do odpowiedniej listy, jeśli jeszcze go tam nie ma.
- [`addCardmarketPrice.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/businessLogic/addCardmarketPrice.mongodb.js) - dodanie ceny danej karty jako cena z [Cardmarket](https://www.cardmarket.com/en). Funkcja znajduje `uuid` karty na podstawie jej nazwy i dodaje podaną cenę z aktualną datą.
- [`addDeckList.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/businessLogic/addDeckList.mongodb.js) - dodanie informacji o talii. Funkcja waliduje typ talii oraz automatyczne generuje `fileName` na podstawie nazwy i kodu talii.

Na początku implementując `addCardmarketPrice` nadpisywałem cały dokument w `$set`. Traciłem przez to ceni z poprzednich dni.
Na forum @mongodb-community:update-collection-item-without-removing-non-existing-values znalazłem rozwiązanie, że należy użyć _Dot Notation_ @mongodb:dot-notation, żeby zaktualizować tylko wybrane pola.

Uznałem, że w moim przypadku **sekwencje do autoinkrementacji** nie są potrzebne.
Szczególnie w środowiskach rozproszonych używanie tego typu sekwencji może sprawiać problemy z synchronizacją wartości. Na przykład w sytuacji równoległego dodania dwóch dokumentów.
Gdybym w przyszłości potrzebował sekwencji, to zaimplementowałbym je bazując na artykule _MongoDB Auto-Increment_ @mongodb:auto-increment.

Agregację danych wykonałem w zapytaniach testujących relacje.
Przygotowałem też nowe zapytanie wyliczające podstawowe statystyki dla danej talii w pliku [`deckStatistics.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/businessLogic/deckStatistics.mongodb.js).

- [`usingNestedData.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/relations/usingNestedData.mongodb.js) - wyszukanie najczęstszych słów kluczowych
- [`mostExpensiveStandardCards.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/relations/mostExpensiveStandardCards.mongodb.js) - wyszukanie najdroższych kart legalnych w standardzie
- [`deckStatistics.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/businessLogic/deckStatistics.mongodb.js) - wyliczenie podstawowych statystyk talii

Analogiczne elementy, które warto dodać w pełnej wersji aplikacji:

- funkcje do dodawania cen dla innych sklepów i cen wersji online
- funkcję do dodawania i aktualizacji typów kart
- funkcję do dodawania nowych kart lub aktualizacji istniejących
- funkcję do dodawania i aktualizacji setów
- funkcję do dodawania i aktualizacji szczegółowych informacji o taliach
- analiza trendów cen danych kart
- wyliczenie wartości kolekcji podanych kart
- rozbudowanie wyliczania statystyk dla danej talii o więcej parametrów

# Indeksy {#sec-indexes}

Używając zapytania wyszukującego najdroższe karty, zauważyłem, że było ono bardzo wolne.
Przypuszczam, że wynika to z operacji `$lookup`.
Żeby to zweryfikować użyłem metody `explain`.
Pozwala ona przeanalizować dane o wykonaniu zapytania, takie jak czas poszczególnych etapów @mongodb:analyze-query-performance. \
Za pomocą `explain("executionStats")` zbadałem czas wykonania poszczególnych etapów zapytania (@tbl-query-analysis-before-index).

| Etap | Czas wykonania etapu (ms) | Całkowity czas (ms) |
|-------|----------------|-----------------|
| $unwind | 10 | 10 |
| $limit | 0 | 10 |
| $project | 0 | 10 |
| $lookup | 7047 | 7057 |
| $addFields | 0 | 7057 |
| $sort | 0 | 7057 |
| $project | 0 | 7057 |

: Czas zapytania przed dodaniem indeksu {#tbl-query-analysis-before-index}

Widać, że największy narzut pochodzi z etapu `$lookup` (@tbl-query-analysis-before-index).
Ponieważ `$lookup` wyszukuje dokumenty w kolekcji `allPrices` po polu `uuid`, to dodanie indeksu powinno to przyśpieszyć.

Dodałem indeks na polu `cardUuid` w kolekcji `allPrices` za pomocą skryptu [`createIndexes.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/indexes/createIndexes.mongodb.js).


| Etap | Czas wykonania etapu (ms) | Całkowity czas (ms) |
|-------|----------------|-----------------|
| $unwind | 5 | 5 |
| $limit | 0 | 5 |
| $project | 0 | 5 |
| $lookup | 27 | 32 |
| $addFields | 0 | 32 |
| $sort | 0 | 32 |
| $project | 0 | 32 |

: Czas zapytania po dodaniu indeksu {#tbl-query-analysis-after-index}

Po ponownym przeanalizowaniu zapytania widać, że czas etapu `$lookup` zmniejszył się z 7047 ms do 27 ms (@tbl-query-analysis-after-index).
Jest to bardzo znacząca poprawa wydajności. \
Podobnie jak w przypadku kluczy obcych w bazach relacyjnych, indeksy są kluczowe dla zaczytywania danych z innych kolekcji.

Żeby uniknąć wpływu cache na testy wydajności usuwałem kontener z bazą i tworzyłem go ponownie pomiędzy testami.

Zachęcony poprawą wydajności usunąłem ograniczenie brania tylko 100 pierwszych kart i przeanalizowałem ceny wszystkich 6440 kart ze standardu.
Zapytanie, które wcześniej wykonywało się tak długo, że nie chciałem na nie czekać, teraz wykonało się poniżej 1 sekundy!

Gracze często szukają kart po ich nazwach.
Żeby to przyśpieszyć dodałem indeksy na nazwach kart.
W kolekcji `standardAtomic` dodałem zwykły indeks _Single Field_ @mongodb:single-field-indexes na polu `name`, a w kolekcji `standard` na polu `cards.name` indeks _Multikey_ @mongodb:multikey-indexes.
Dodałem podobne indeksy do wyszukiwania innych elementów po ich nazwach lub kodach. \
Tego typu indeksy testowałem analizując statystyki wykonania z włączonym i wyłączonym indeksem w pliku [`cardSearchByName.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/indexes/cardSearchByName.mongodb.js).

Gracze często szukają kart do swoich talii bazując na kolorze karty i jej koszcie many.
Żeby przyśpieszyć tego typu wyszukiwania utworzyłem _Compound Index_ @mongodb:compound-indexes.
Ponieważ tylko przednia strona karty jest istotna przy tego typu wyborze, ustawiłem indeks na pierwszym elemencie listy stron kart (@lst-compound-index). \
Indeksy na tego typu zagniezdzonych wartościach nie są możliwe do utworzenia w relacyjnych bazach danych, gdzie indeksuje się całe kolumny.

```{#lst-compound-index .js lst-cap="Utworzenie indeksu złożonego"}
db.standardAtomic.createIndex({ "sides.0.colors": 1 }, { "sides.0.manaValue": 1 });
```

W indeksach złożonych kolejność pól ma istotne znaczenie.
Kierowałem się zasadą ESR @mongodb:esr-indexing-guideline, najpierw wybierając kolor, po którym użytkownicy będą zazwyczaj bezpośrednio filtrować, a potem dając koszt many, który będzie częściej wyszukiwany w zakresach. \
W ten sposób dane o wartościach many w ramach danego koloru są **ułożone obok siebie w indeksie**, zapytania tego typu są wydajne. \
Testując zapytania tego typu w pliku [`cardForDeckSlot.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/indexes/cardForDeckSlot.mongodb.js) ustaliłem, że indeks znacząco przyśpiesza wyszukiwanie.

Ponieważ z czasem w \acr{MTG} pojawiają się nowe formaty, na obiekcie opisującym legalność karty ustawiłem indeks _Wildcard_ @mongodb:wildcard-indexes poleceniem z @lst-wildcard-index. \
Dzięki temu rodzajowi indeksu nie muszę jawnie podawać pól, które będą indeksowane.
Indeks obejmie wszystkie pola zagnieżdżone pod `sides.legalities`, nawet gdy z czasem dojdzie nowy rodzaj formatu. \
Indeksy tego rodzaju raczej nie występują w bazach relacyjnych.

```{#lst-wildcard-index .js lst-cap="Utworzenie indeksu typu Wildcard"}
db.standardAtomic.createIndex({ "sides.legalities.$**": 1 });
```

Pozostałe indeksy, które założyłem są w pliku [`createIndexes.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/indexes/createIndexes.mongodb.js).


<!-- Można robić indeksy na zagniezdzonych dokumentach, wtedy jeśli zapytanie podaje cały zagnieżdżony dokument to indeks jest używany -->
<!-- Hashed Sharding -->
<!-- Multikey Indexes -->
<!-- Założenie niektórych typów indeksów ogranicza schemat dokumentów np. compound multikey index może mieć tylko jedną tablicę -->
<!-- Wildcard indexes -->
<!-- Domyślne wsparcie dla indeksów przestrzennych -->
<!-- Indeksy TTL -->
<!-- Indeksy tekstowe -->
<!-- Indeksy wildcard text -->
<!-- Create index jest idempotentne -->

# Transakcje

Transakcje w MongoDB działają tylko, gdy system składa się z więcej niż jednej repliki @mongodb:transactions-production-consideration.
Żeby je przetestować skonfigurowałem dodatkowe instancje w [`docker-compose.yml`](https://github.com/christopher-dabrowski/BoardBase/blob/main/docker-compose.yml). \
Moją konfigurację bazowałem na artykule _Create a replica set in MongoDB with Docker Compose_ @tericcabrel:mongodb-replica-set-docker-compose.
Uprościłem konfigurację sieciową, w stosunku do proponowanej w artykule, korzystając z domyślnej sieci tworzonej przez Docker Compose @docker-compose:networking.
Zautomatyzowałem też inicjalizację połączenia replik skryptem [`replica-set-init.sh`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/replica-set-init.sh) za pomocą Docker Compose lifecycle hook'u `post_start`. Konfiguracja sugerowana w artykule wymagała ręcznego uruchomienia skryptu po uruchomieniu kontenerów.

Zauważałem, że po skonfigurowaniu replik moje połączenia z Playgrounds @mongodb:playgrounds i \acr{Compass} przestały działać.
Po przeczytaniu wątku na forum _Cannot connect to replica set via mongo compass_ @mongodb-community:cannot-connect-to-replica-set-via-mongo-compass zrozumiałem, że muszę dostosować connection string. \
Na początku wypróbowałem `directConnection=true`, co sprawiło, że połączenie zadziałało.
W tej konfiguracji jednak łączyłem się tylko z główną repliką, co w sytuacji potencjalnej awarii neguje zalety używania replik. \
Idąc za radami z forum @mongodb-community:cannot-connect-to-replica-set-via-mongo-compass dodałem nowe routing do `/etc/hosts` (@lst-mongo-replica-set-hosts).
Po tej zmianie udało mi się połączyć connection string'iem `mongodb://admin:*****@mongodb:27017,mongodb-secondary1:27018,mongodb-secondary2:27019/?replicaSet=rsmtg` do wielu replik.

```{#lst-mongo-replica-set-hosts .plaintext lst-cap="Routing do replik MongoDB w /etc/hosts"}
127.0.0.1 mongodb
127.0.0.1 mongodb-secondary1
127.0.0.1 mongodb-secondary2
```

Poprawne działanie replik widać między innymi uruchamiając `db.runCommand({ hello: 1 })` (@lst-mongo-replica-set-hello).

```{#lst-mongo-replica-set-hello .json lst-cap="Odpowiedź z polecenia hello po skonfigurowaniu replik"}
{
  "topologyVersion": {
    "processId": {
      "$oid": "69357bfa954b1bf67799cd35"
    },
    "counter": 7
  },
  "hosts": [
    "mongodb:27017",
    "mongodb-secondary1:27017",
    "mongodb-secondary2:27017"
  ],
  "setName": "rsmtg",
  "setVersion": 1,
  "isWritablePrimary": true,
  "secondary": false,
  "primary": "mongodb:27017",
  "me": "mongodb:27017",
  "electionId": {
    "$oid": "7fffffff0000000000000007"
  },
// Skrócony wynik ...
}
```

Przykładową transakcję przygotowałem w pliku [`updateSetName.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/transactions/updateSetName.mongodb.js). Aktualizuje ona nazwę dodatku w kilku kolekcjach. \
Dla transakcji skonfigurowałem odpowiedni `readConcern` i `writeConcern` @mongodb:read-concern @mongodb:write-concern. \
Po skonfigurowaniu replik, za równo przy połączeniu z `directConnection` jak i listą replik, transakcja działała poprawnie.
Jednak to drugi rodzaj połączenia uważam za prawdziwe zastosowanie rozproszonych transakcji @mongodb:transactions.

# Zaawansowane funkcjonalności

Wybrane zaawansowane funkcjonalności MongoDB, które pasują do mojego zbioru danych.

## Przetwarzanie grafów

W \acr{MTG} z danymi dodatkami wypuszczane są dodatkowe produkty, takie jak zestawy promocyjne kart z innymi grafikami.
Do reprezentacji tej relacji w mojej bazie wykorzystywane jest pole `parentSet` w kolekcji `setList`.

Powiązania produktu innymi produktami mogą być wielopoziomowe.
Przykładowo dodatek _Outlaws of Thunder Junction_ ma rozszerzenie _The Big Score_, do którego został wydany zestaw promocyjny _The Big Score Promos_.
Z tego powodu chcąc zobaczyć wszystkie suplementarne produkty nie wystarczy wyszukać `{parentSet: baseSetCode}`.

Sądzę, że do analizy tego typu relacji idealnie nadaje się mechanizm przetwarzania grafów @mongodb:mongodb-as-graph-database.
Przejście wielu poziomów relacji można bardzo prosto zrealizować `$graphLookup`. \
Zapytanie, które wykorzystuje przetwarzanie grafów do znalezienia produktów powiązanych z zadanym napisałem w pliku [`graphQueries.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/advancedFeatures/graphQueries.mongodb.js)

## Indeks klastrowany

Tworząc kolekcję można ustawić `_id` jako indeks klastrowany.
Dokumentacja zaleca to podejście, ponieważ pozwala ono często na wyelimniowanie jednego zwykłego indeksu, zmniejsza rozmiar kolekcji i przyśpiesza zapytania @mongodb:clustered-collections.
Postanowiłem to przetestować.

Wybrałem kolekcję `allPrices`, ponieważ mierzyłem już czytanie z niej szukając najdroższych kart w @sec-indexes. \
Ponieważ indeks kastrowany można utworzyć tylko przy tworzeniu kolekcji @mongodb:clustered-collections usunąłem ją i utworzyłem ponownie [`clusteredCollection.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/advancedFeatures/clusteredCollection.mongodb.js).
Zmieniłem wczytywanie danych do kolekcji `allPrices`, umieszczając w `_id` wartość `cardUuid` [`importAllPricesToday.sh`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/importData/importAllPricesToday.sh).
Żeby nie musieć przerabiać poprzednich zapytań zostawiłem też jawne pole `cardUuid`.

Po skonfigurowaniu indeksu klastrowanego zmieniłem zapytanie wyszukujące nadroższe karty, żeby z niego skorzystać [`mostExpensiveStandardCards-withClusteredIndex.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/advancedFeatures/mostExpensiveStandardCards-withClusteredIndex.mongodb.js).
Następnie zbadałem czas wykonania zapytań.

Dla spólnego porównania ograniczyłem liczbę przetwarzanych kart do 100.
Czas zapytania spadł do 9 ms (@tbl-most-expensive-with-clustered-index).
Przy stosowaniu zwykłego indeksu zapytanie trwało 32 ms (@tbl-query-analysis-after-index). \
Przetestowałem też czas wykonania zapytania dla wszystkich 6440 kart.
Dla indeksu klastrowanego czas wyniósł 410 ms, a dla zwykłego indeksu trwał około 900 ms.

| Etap | Czas wykonania etapu (ms) | Całkowity czas (ms) |
|-------|----------------|-----------------|
| $unwind | 1 | 1 |
| $limit | 0 | 1 |
| $project | 0 | 1 |
| $lookup | 8 | 9 |
| $addFields | 0 | 9 |
| $sort | 0 | 9 |
| $project | 0 | 9 |

: Wyszukanie najdroższych kart z indeksem klastrowanym (tylko pierwsze 100 kart) {#tbl-most-expensive-with-clustered-index}

Stosowanie indeksu klastrowanego znacząco przyśpieszyło moje zapytanie, nawet w stosunku do zwykłego indeksu.
Zdecydowanie będę korzystał z tej funkcjonalności w przyszłości. \
Ciekawe było też dla mnie to, że przy analizie zapytania korzystającego z indeksu klastrowanego `explain("executionStats")` pokazuje, że nie został użyty żaden indeks `"indexesUsed": [],`.
Jestem jednak pewien, że indeks klastrowany został użyty, ponieważ w przeciwnym razie wykonanie trwałoby znacznie dłużej.

## Map Reduce

Byłem ciekaw ile w danym roku zostało wydanych setów w ramach danych bloków (rodzajów). Chciałem też zobaczyć jak zmienia się to na przestrzeni lat.

Wykorzystałem do tego podejście map reduce w pliku [`mapReduce.mongodb.js`](https://github.com/christopher-dabrowski/BoardBase/blob/main/mongo/advancedFeatures/mapReduce.mongodb.js) \
Najpierw zmapowałem każdy dokument mający `releaseDate` i `block` na rok i nazwę bloku.
Następnie w funkcji redukującej wyliczyłem liczbę setów dla danego roku i bloku.
Na koniec, już poza map reduce, posortowałem wyniki po roku.

Całkiem wygodnie pisało mi się to zapytanie w formie map reduce.
Było to dla mnie łatwiejsze niż napisanie analogicznego zapytania jako `aggregate`, choć myślę, że może to wynikać z mojej małej wprawy w zapytaniach `aggregate`. \
W map reduce brakowało mi możliwości posortowania wynków. Zrobiłem je osobno zwykłym `sort` na końcu.
Warto uwzględnić, że używanie map reduce nie jest już zalecane @mongodb:map-reduce. Z tego powodu nie będę raczej wracał do tej funkcjonalności.

# Wnioski

<!-- max 1/2 strony -->

Implementacja bazy do analizy danych o kartach \acr{MTG} w MongoDB zawiera kilka istotnych różnic w stosunku do podobnego systemu zrobionego na bazie relacyjnej.

Główną różnicę, którą odczułem jest **inne podejście do modelowania danych**.
W bazach relacyjnych stosuje się zazwyczaj 3NF, a w MongoDB typowe jest zagnieżdżanie i duplikacja danych @mongodb:data-modeling-best-practices.
Takie podejście prowadzi do znacznie **szybszych i prostszych zapytań**.
Jednak umożliwia **łatwą utratę spójności bazy**, gdy na przykład zwielokrotnione dane zostaną zmienione tylko w jednym miejscu.

Baza MongoDB odchodzi od architektury ANSI-SPAC.
Posiada ona widoki, ale nie daje możliwości ich edycji.
Cho prawda w bazach relacyjnych trudno uzyskać działanie edycji widoków, jednak jest to teoretycznie możliwe.

MongoDB nie posiada bezpośrednio wyzwalaczy.
Logika zapewniająca spójność musi znajdować się po stronie aplikacji, może to być jednak trudne, gdy różne aplikacje korzystają z tej samej bazy.
Atlas oferuje wyzwalacze @mongodb-atlas:database-triggers, jednak ja korzystałem z lokalnej bazy.
Efekt podobny do wyzwalaczy można osiągnąć korzystając z _Change Streams_ @mongodb:change-streams, jest to jednak bardziej skomplikowane.

Konfiguracja replikacji jest zdecydowanie prostsza w MongoDB niż w relacyjnych bazach danych.

Brak silnego schematu utrudnia to odpytywanie bazy, ponieważ nie można być pewnym jakie pola są dostępne w dokumentach ani nawet, że wszystkie ich wartości będą tego samego typu.

Mimo, że to był mój pierwszy kontakt z MongoDB, to pracowało mi się zdecydowanie przyjemnie.
Może to wynika z mojego większego doświadczenia z JavaScriptem niż \acr{SQL}, jednak gdybym miał wybierać z jaką bazą przyjdzie mi pracować, to pewnie wybrałbym MongoDB.


# Źródła {.unnumbered}

::: {#refs}
:::
