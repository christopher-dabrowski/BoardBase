---
title: Projekt BoardBase
subtitle: Sprawozdanie z Etapu 2 - Zaawansowane systemy baz danych
format:
  pdf:
    output-file: Etap 2 Sprawozdanie Krzysztof Dąbrowski 293101.pdf
    toc: true
    lof: true
    code-overflow: wrap
    lot: true
    # fig-pos: 'H'
---

\listoflistings

{{< include ../shared/repo_callout.qmd >}}

# Funkcje i procedury dodawania elementów

## Funkcja
Przeczytałem, że liczenie arytmetycznej średniej ocen jest mało miarodajne dla małej liczby ocen, a użycie średniej bayesowskiej jest lepszym rozwiązaniem @algolia:bayesian-average. Napisałem \acr{UDF} liczącą w ten sposób średnią ocenę gry.

Dla gry z 5 pozytywnymi ocenami średnia arytmetyczna wychodziła 8.8, a wynik mojej \acr{UDF} [`fair_game_rating`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/user-defined-functions.sql) wyniósł 8.48(6).

## Procedury dodawania elementów

Utworzyłem kilka procedur do dodawania nowych rekordów do bazy danych w pliku [`create-records-procedures.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/create-records-procedures.sql).

- `add_user` dodaje nowego użytkownika,
- `add_location` dodaje nowe miejsce do grania,
- `add_rating` dodaje nową ocenę gry,
- `add_review` dodaje nową recenzję,
- `add_game_wish` dodaje nową grę do listy życzeń.

Procedura `add_user` automatycznie wylicza hash hasła i przycina białe znaki z nazwy użytkownika i adresu email. \
Pozostałe procedury ułatwiają ustawiają automatycznie id użytkownika na pasujące do aktualnie zalogowanego użytkownika do bazy za pomocą `WITH` z \acr{CTE}.

## Dokumentacja działania

Przy testowaniu procedur miałem kłopot z deklarowaniem zmiennych. Jestem przyzwyczajony do deklarowania zmiennych w ramach sesji \acr{SQL} za pomocą zwykłego `DECLARE` \@nazwa zmiennej. \
Przeczytałem, że w PostgreSQL trzeba deklarować zmienne w blokach @postgres-docs:declarations.
Do tego dowiedziałem się, że w blokach nie mogę używać `SELECT` do wyświetlania wartości. Zamiast tego użyłem `RAISE NOTICE` @stackoverflow:how-to-perform-a-select-query-in-a-do-block.

Na początku nie działało mi tworzenie nowego użytkownika procedurą `add_user`. \
Przypominałem sobie, że na poprzednim etapie ustawiłem uprawnienia do tworzenia użytkowników i tylko administratorzy mogą to robić. Przełączyłem się na konto administratora i procedura zadziałała.

```txt
NOTICE: Created user: 1015
```

Zmieniłem użytkownika na _casual_gamer_ i wykonałem kolejne procedury z mojego testowego pliku [`try-simple-insert-procedures.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/tests/try-simple-insert-procedures.sql).

```text
NOTICE: Created location: 11
NOTICE: Created rating: 61
NOTICE: Created review: 19
NOTICE: Created game wish: 16
```

Utworzenie rekordów sprawdziłem też zapytaniami `SELECT`.

# Złożona procedura

Czasem zdarza się, że użytkownik posiada na kilka kont w systemie na przykład zalogowane mailem i założone za pośrednictwem konta dużego serwisu takiego jak na przykład Google. \
W takiej sytuacji, której sam kiedyś doświadczyłem, użytkownik po jakimś czasie może chcieć połączyć swoje konta w jedno.

W tym celu przygotowałem procedurę [`merge_user_accounts`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/complex-procedure.sql), która pozwala zmigrować dane z jednego konta do drugiego. \
Wszystkie aktualizacje danych są wykonywane w ramach transakcji. Dzięki temu baza przejdzie ze stanu spójnego do spójnego lub cofnie wszystkie zmiany.

Procedura sprawdza czy użytkownicy istnieją i czy są różni. Jeśli tak, to wykonuje następujące kroki:

1. Migruje oceny gry,
2. Migruje recenzje,
3. Migruje listy życzeń,
4. Migruje kolekcję gier,
5. Migruje lokalizacje,
6. Migruje dziennik rozegranych gier,
7. Usuwa stare konto.

Na każdym etapie sprawdzane jest czy użytkownik nie ma już danych wartości na docelowym koncie. Jeśli to możliwe, to dane są aktualizowane, a w przeciwnym razie dane starego konta są usuwane.

## Dokumentacja działania

Do przetestowania transakcji w procedurze zasymulowałem błąd pod koniec dodając `RAISE EXCEPTION`.

```sqlpostgresql
CALL merge_user_accounts(9, 10);
SELECT * FROM user_game_release WHERE user_id = 9;
```

Logi procedury:

```text
{{< include listings/user-merge-procedure-fail.txt >}}
```

Po wynikach `SELECT` @tbl-games-after-failed-merge widać, że dane nie zostały zmigrowane, a mechanizm transakcji cofnął zmiany

| user_id | game_release_id |    acquired_at        |
|---------|-----------------|----------------------|
|   9     |      25         | 2016-02-05 14:00:00  |
|   9     |      28         | 2015-03-20 15:45:00  |
|   9     |      33         | 2019-11-01 17:15:00  |

: Gry użytkownika źródłowego po nieudanym wykonaniu procedury {#tbl-games-after-failed-merge}

Gdy usunąłem ręcznie rzucenie wyjątku, dane dane użytkownika zostały poprawnie przeniesione, a zapytanie `SELECT` @tbl-games-after-successful-merge nie zwróciło żadnych wyników.

```text
{{< include listings/user-merge-procedure-success.txt >}}
```

| user_id | game_release_id |    acquired_at        |
|---------|-----------------|----------------------|

: Gry użytkownika źródłowego po poprawnym wykonaniu procedury {#tbl-games-after-successful-merge}

# Wyzwalacze

Chciałem, żeby gdy użytkownik wejdzie w posiadanie gry została ona automatycznie usunięta z jego listy życzeń. W tym celu przygotowałem wyzwalacz, który to automatyzuje.

Mój pomysł na logikę biznesową zakłada, że zapisują informację o rozgrywce (`play`) można podać większą liczbę uczestników (`player_count`) niż powiązanych graczy, ponieważ nie każdy uczestnik musi mieć konto w systemie.
Może to jednak prowadzić do błędnej sytuacji podania mniejszej liczby `player_count` niż powiązanych graczy. \
Przygotowałem wyzwalacz, który przy dodaniu relacji na większą liczbę graczy niż `player_count` aktualizuje `player_count` na większą wartość oraz drugi, który pilnuje, żeby `player_count` nie był ustawiony na mniejszą wartość niż liczba faktycznych graczy.

W PosgreSQL wyzwalacz musi wywoływać funkcję lub procedurę @postgres-docs:createtrigger, więc do każdego wyzwalacza stworzyłem też odpowiadającą procedurę. \
Kod wyzwalaczy umieściłem w pliku [`triggers.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/triggers.sql).

## Dokumentacja działania

Dla użytkownika `casual_gamer` dodałem grę _Pandemic_ do jego listy życzeń @tbl-wishlist-after-pandemic-add.

```postgresql
CALL add_game_wish(4, NULL);
```

Sprawdziłem listę życzeń użytkownika.

|username    |name    |wished_at                 |
|------------|--------|--------------------------|
|casual_gamer|Pandemic|2025-11-07 10:39:01.453507|
|casual_gamer|Splendor|2024-09-20 14:00:00       |
|casual_gamer|Gloomhaven|2024-08-20 16:45:00       |

: Życzenia użytkownika `casual_gamer` po dodaniu gry _Pandemic_ do listy życzeń {#tbl-wishlist-after-pandemic-add}

Po dodaniu gry _Pandemic_ do kolekcji użytkownika automatycznie zniknęła ona z jego listy życzeń @tbl-wishlist-after-acquire-pandemic.

|username    |name    |wished_at                 |
|------------|--------|--------------------------|
|casual_gamer|Splendor|2024-09-20 14:00:00       |
|casual_gamer|Gloomhaven|2024-08-20 16:45:00       |

: Życzenia użytkownika `casual_gamer` po dodaniu gry _Pandemic_ do kolekcji {#tbl-wishlist-after-acquire-pandemic}

Kod użyty do testów umieściłem w pliku [`test-wishlist-trigger.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/programmable/tests/test-wishlist-trigger.sql).

# Inne elementy ograniczenia dostępu

Do tej pory przygotowałem już **18** elementów ograniczenia dostępu z **10 sugerowanych** w zakresie zadania.

- 5 procedur dodawania danych
- 1 złożona procedura
- 3 wyzwalacze
- 4 widoki użytkownika
- 1 widok administratora
- 4 widoki publiczne

Z tego powodu ograniczę się do zastanowienia, co jeszcze byłoby warto dodać w produkcyjnej aplikacji.

- widok statystyk użytkownika
- widok historii ceny danej edycji gry
- widok personalizowanych rekomendacji gier
- wyzwalacze pilnujące czy zwycięzca rozgrywki jest jej uczestnikiem

Sporą część zachowania spójności zapewniają już instrukcje kaskadowego usuwania powiązanych rekordów, które skonfigurowałem tworząc tabele.

# Automatyzacja zadania

## Wybór scheduler'a

Żeby uruchamiać automatycznie kod `SQL` w bazie zdecydowałem się użyć rozszerzenia [pg_cron](https://github.com/citusdata/pg_cron), o którym słyszałem w filmie _I replaced my entire tech stack with Postgres..._
 @youtube:IReplacedMyEntireTechStackWithPostgres.

Rozważałem użycie scheduler'a [pgAgent](https://www.pgadmin.org/docs/pgadmin4/9.9/pgagent.html), ale po przeczytaniu artykułu porównującego te rozwiązania @medium:comparing-postgresql-job-schedulers-pg-cron-vs-pgagent i tabeli różnić @github:pg-agent-vs-pg-cron, uznałem, że [pg_cron](https://github.com/citusdata/pg_cron) bardziej mi pasuje, ponieważ jest lżejszym rozwiązaniem i nie wymaga oddzielnego demona.
Gdyby zadanie wymagało zaawansowanej logiki uruchamiania zadań w czasie i zależności między zadaniami pewnie wybrałbym[pgAgent'a](https://www.pgadmin.org/docs/pgadmin4/9.9/pgagent.html).

## Instalacja

Żeby zainstalować rozszerzenie nie mogłem już korzystać z domyślnego obrazu Docker @docker:postgres-official-image i musiałem skonfigurować własny obraz, który bazuje na tym bazowy, na którym zainstaluję rozszerzenie.
Znalazłem obraz z od razu zainstalowanym rozszerzeniem pg_cron @docker:postgres-pg-cron-image, ale używa on starej wersji Postgres, więc wolałem stworzyć swój.

Przygotowałem własny obraz z zainstalowanym rozszerzeniem pg_cron w pliku [`Postgres.Dockerfile`](https://github.com/christopher-dabrowski/BoardBase/blob/main/Postgres.Dockerfile), zmieniłem plik [`docker-compose.yml`](https://github.com/christopher-dabrowski/BoardBase/blob/main/docker-compose.yml), żeby używał tego obrazu i skonfigurowałem \acr{SZBD} w pliku [`postgresql.conf`](https://github.com/christopher-dabrowski/BoardBase/blob/main/postgresql.conf).

Po skonfigurowaniu obrazu Docker okazało się, że nie uruchamia się kontener. Pojawiał się błąd, że w obrazach w wersji 18+ volumen musi być zamontowany poziom wyżej w kontenerze.
Zdziwiło mnie to, ponieważ wcześniej używałem po prostu obrazu `18.0`, a ten błąd nie występował. \
Przywróciłem konfigurację Docker Compose do używania bezpośrednio bazowego obrazu, ale błąd dalej występował.
Poprawiłem więc ścieżkę volumenu, co rozwiązało problem, choć dalej zastanawia mnie, dlaczego wcześniej nie miałem tego problemu. \
Przypuszczam, że został wgrany nowy obraz pod tag `18.0`, a przygotowanie mojego obrazu sprowokowało `docker pull`.

## Automatyczne zadanie

Pomyślałem, że użytkownicy często chcieliby przeglądać statystyki gier. Niektóre ze statystyk wymagają agregacji.
Ponieważ wyliczanie niektórych agregacji jest czasochłonne, a użytkownicy nie oczekują raczej w pełni aktualnych statystyk (pewnie wyniki z ostatniego dnia będą dobre), to utworzyłem zmaterializowany widok przechowujący te dane. \
Za pomocą automatycznego zadania [pg_cron](https://github.com/citusdata/pg_cron), skonfigurowanego w pliku [`automation.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/automation/automation.sql), aktualizuję ten widok codziennie o 3 w nocy. \
Skonfigurowane zadanie widać w wyniku poniższego zapytania w @tbl-automation-jobs.

```sqlpostgresql
SELECT jobid, schedule, command
FROM cron.job
```

|jobid|schedule |command                                             |
|-----|---------|----------------------------------------------------|
|1    |0 3 * * *|REFRESH MATERIALIZED VIEW main.game_popularity_stats|

: Automatyczne zadania {#tbl-automation-jobs}

\acr{SQL} widoku zapisałem w pliku [`game-stats-materialized-view.sql`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/views/game-stats-materialized-view.sql). Widok wylicza między innymi bayesowską średnią ocenę gry, którą zaimplementowałem wykorzystując moją \acr{UDF} `fair_game_rating`, liczbę gier rozegranych w ostatnich 90 dniach, czy też customowy ranking popularności, który wyliczam heurystycznie na podstawie kilku innych parametrów i inne statystyki.

# Kopia zapasowa

## Wybór podejścia
Zastanawiałem się nad wyborem między trzema głownymi podejściami do backupu @postgres-docs:backup-and-restore:

1. \acr{SQL} dump,
2. backup plików bazy danych,
3. backup plików i \acr{WAL} z odtwarzaniem bazy point in time z \acr{WAL}.

Uznałem, że podejście bazujące na \acr{WAL} jest zbyt złożone na moje potrzeby, gdy zapoznałem się z mechanizmem jego działania @postgres-docs:backup-online-wal. \
Podejście drugie wymaga zatrzymania \acr{SZBD}, co sprawia, że w produkcyjnych środowiskach jest mało praktyczne.
Dokumentacja sugeruje, żeby raczej używać podejścia bazującego na \acr{SQL} dump @postgres-docs:backup-file, więc to na nie się zdecydowałem.

## Wykonanie kopii zapasowej

Zgodnie z zaleceniami z dokumentacji @postgres-docs:backup-dump, użyłem narzędzia `pg_dump` do zrobienia backupu. \
Za pierwszym razem narzędzie `pg_dump` nie zadziałało, ponieważ okazało się, że domyślny pakiet [homebrew](https://brew.sh/) instaluje wersję 14, a mój \acr{SZBD} jest w wersji 18.
Na szczęście przyczyna błędu była dobrze opisana w komunikacie i wystarczyło zainstalować odpowiednią wersję. Zrobiłem to poleceniem `brew install postgresql@18`.

Ponieważ przeczytałem, że domyślnie `pg_dump` loguje się do bazy taką samą nazwą użytkownika @postgres-docs:backup-dump, jak zalogowane konto, to nadpisałem nazwę użytkownika i kilka innych podstawowych parametrów w wywołaniu.

```sh
pg_dump --dbname=boardbase --username=postgres --host=localhost --file=2025-11-10_boardbase_backup.sql
```

Zgodnie z moimi oczekiwaniami powstały plik zawiera kod \acr{SQL} do odtworzenia schematu bazy, danych, a nawet utworzonego rozszerzenia.
Zawiera nawet konfigurację mojego cron joba.

## Weryfikacja kopii zapasowej

Żeby sprawdzić poprawność kopii zapasowej postanowiłem odtworzyć z niej bazę danych.

Do kontenera z \acr{SZBD} zamontowałem nowy volumen. \
Przed wgraniem kopii zapasowej utworzyłem użytkowników, ponieważ skrypt kopii nie tworzy użytkowników @postgres-docs:backup-dump.
W moim skrypcie [`1_create-groups`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/users/1_create-groups.sql) tworzę grupy i nadaję im role.
Ponieważ nie powstał jeszcze schemat `main`, to nadanie do niego ról nie zadziałało. Nie jest to problem, ponieważ przypisanie uprawnień jest zawarte w kopii zapasowej. \
Po utworzeniu grup, mogłem stworzyć użytkowników i przypisać ich do grup skryptem [`2_craete-users`](https://github.com/christopher-dabrowski/BoardBase/blob/main/sql/users/2_craete-users.sql).

Wczytałem kopię zapasową i spróbowałem uruchomić kilka zapytań. \
Okazało się, że **zapytania, w których nie podawałem jawnie nazwy schematu, nie działały**. \
Sprawdziłem, i okazało się, że w pliku backupu **nie ma mojej instrukcji zmiany domyślnego `search_path`**, żeby zawierał schemat `main`.
Wykonałem ją ręcznie. Wtedy zapytania działały już poprawnie.

# Inny \acr{SZBD}

Wybrałem \acr{SZBD} MS SQL Server.
Używałem go pośrednio w pracy w aplikacjach backendowych przez \acr{ORM} i chciałbym lepiej poznać tą technologię.

Tak jak w przypadku Postgres, zdecydowałem się na uruchomienie MS SQL Serwer w kontenerze Docker skonfigurowanym w pliku [`docker-compose.yml`](https://github.com/christopher-dabrowski/BoardBase/blob/main/docker-compose.yml). \
Przy konfiguracji kontenera wzorowałem się na oficjalnej dokumentacji @ms-learn:docker-run-containers-for-sql-server-on-linux.
Nie chciałem jednak używać obrazu _latest_, jak rekomenduje dokumentacja @ms-learn:docker-run-containers-for-sql-server-on-linux, ponieważ sądzę, że nie jest to dobra praktyka, ponieważ jest on automatycznie zmieniany. \
Na szczęście dokumentacja sugeruje alternatywnie użycie konkretnej wersji obrazu `mcr.microsoft.com/mssql/server:2025-GA-ubuntu`.
Zdziwiłem się jednak, gdy spróbowałem pobrać ten obraz, ponieważ okazało się, że **taki obraz nie istnieje**. \
Sprawdziłem to na oficjalnej liście tagów tego obrazu @microsoft-artifact-registry:mssql-server-tags.
Spojrzałem też na informację o aktualnych wersjach SQL Server @ms-learn:latest-updates-and-version-history-for-sql-server, gdzie dowiedziałem się, że wersja 2025 nie została jeszcze oficjalnie wydana, co sugerował podany w dokumentacji @ms-learn:docker-run-containers-for-sql-server-on-linux tag `2025-GA-ubuntu`, gdzie w nomenklaturze Microsoft GA oznacza publicznie wydaną wersję. \
Najwyraźniej **dokumentacja Microsoft @ms-learn:docker-run-containers-for-sql-server-on-linux podaje zmyślony tag do wersji MS SQL Server, która jeszcze nie istnieje**.

Gdy już to zrozumiałem, zdecydowałem się użyć najnowszej stabilnej wersji SQL Server 2022. \
Skonfigurowałem edycję SQL Server na developerską i zmieniłem domyślny Collation @ms-learn:collation-and-unicode-support, tak żeby wspierał kodowanie UTF-8, ponieważ wiem, że większość danych w bazie zmieści się w jednym bajcie UTF-8. \
W oddzielnym artykule dokumentacji @ms-learn:configure-and-customize-sql-server-docker-containers znalazłem informację, gdzie kontener przechowuje dane i zamontowałem tam volumen.

Działanie \acr{SZBD} sprawdziłem za łącząc się z terminala narzędziem [`sqlcmd`](https://learn.microsoft.com/en-us/sql/tools/sqlcmd/sqlcmd-utility?view=sql-server-ver17&tabs=go%2Cwindows-support&pivots=cs1-bash) i pobierając wersję zapytaniem (@lst-query-sql-server-version).

```{#lst-query-sql-server-version .sql lst-cap="Pobranie wersji MS SQL Server"}
SELECT @@VERSION;
GO;
```

Otrzymałem spodziewany wynik (@lst-query-sql-server-version-result).

```{#lst-query-sql-server-version-result .text lst-cap="Wynik zapytania pobierającego wersję MS SQL Server"}
Microsoft SQL Server 2022 (RTM-CU21-GDR) (KB5068406) - 16.0.4222.2 (X64)
	Oct  3 2025 16:55:17
	Copyright (C) 2022 Microsoft Corporation
	Developer Edition (64-bit) on Linux (Ubuntu 22.04.5 LTS) <X64>
```

# Źródła {.unnumbered}

::: {#refs}
:::
